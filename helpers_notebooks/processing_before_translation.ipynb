{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5d95d9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c46489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/robinjaccard/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/robinjaccard/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/robinjaccard/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/robinjaccard/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/robinjaccard/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from deep_translator import GoogleTranslator\n",
    "import swifter\n",
    "import sys\n",
    "sys.path.append('../helpers_python')\n",
    "from pre_processing import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a561cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dccd12",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67745d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the censored tweets\n",
    "dfs = []\n",
    "for r, d, f in os.walk(\"../\"):\n",
    "    for file in f:\n",
    "        if 'withheldtweets.json' in file:\n",
    "            dfs.append(pd.read_json(\"../data/censored_tweets/%s\" % file, lines=True))\n",
    "\n",
    "df_cen = pd.concat(dfs)\n",
    "df_cen = df_cen.dropna(subset=['withheld_in_countries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147776ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'id', 'id_str', 'text', 'source', 'truncated',\n",
       "       'in_reply_to_status_id', 'in_reply_to_status_id_str',\n",
       "       'in_reply_to_user_id', 'in_reply_to_user_id_str',\n",
       "       'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place',\n",
       "       'contributors', 'quoted_status_id', 'quoted_status_id_str',\n",
       "       'quoted_status', 'quoted_status_permalink', 'is_quote_status',\n",
       "       'extended_tweet', 'quote_count', 'reply_count', 'retweet_count',\n",
       "       'favorite_count', 'entities', 'favorited', 'retweeted', 'filter_level',\n",
       "       'lang', 'timestamp_ms', 'linked', 'display_text_range',\n",
       "       'withheld_in_countries', 'extended_entities', 'possibly_sensitive',\n",
       "       'retweeted_status', 'withheld_copyright'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cen.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d871f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cen.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917db557",
   "metadata": {},
   "source": [
    "### Preclean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764f07ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41727, 38)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8111bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_duplicate = df_cen.drop_duplicates(\"text\") # remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4233c944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23081, 38)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_duplicate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a32b76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_t = clean_tweets(df_without_duplicate[\"text\"]) # apply pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc43dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_without_duplicate.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b09104a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['text'] = clean_t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9b7243",
   "metadata": {},
   "source": [
    "### Remove empty tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a0b612",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(725, 38)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[clean_t.apply(lambda x: x.isspace())].shape # number of empty tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e84fcedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clean.drop(df_clean[df_clean.text.apply(lambda x: x.isspace())].index) # remove empty tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f4dac7",
   "metadata": {},
   "source": [
    "### Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1171ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated = df.text.swifter.apply(lambda x: GoogleTranslator(source='auto', target='en').translate(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e41c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['translated'] = translated"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
